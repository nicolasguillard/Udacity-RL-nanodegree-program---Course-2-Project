{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passage de paramètres via un dictionnaire et `**kwargs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 -1 -2\n",
      "1 2 3 -2\n",
      "1 2 3 4\n"
     ]
    }
   ],
   "source": [
    "def f1(a, b, c=-1, d=-2):\n",
    "    print(a, b, c, d)\n",
    "\n",
    "def f2(a, b, f1_args):\n",
    "    f1(a, b, **f1_args)\n",
    "\n",
    "f1(1, 2)\n",
    "f2(1, 2, {'c': 3})\n",
    "f2(1, 2, {'c': 3, 'd': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1(a=1, b=2, c=-1, d=-2)\n",
      "C2(c1=C1(a=10, b=20, c=30, d=-2))\n"
     ]
    }
   ],
   "source": [
    "class C1:\n",
    "    def __init__(self, a=1, b=2, c=-1, d=-2):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        self.d = d\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'C1(a={self.a}, b={self.b}, c={self.c}, d={self.d})'\n",
    "    \n",
    "class C2:\n",
    "    def __init__(self, c1_args: dict):\n",
    "        self.c1 = C1(**c1_args)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'C2(c1={self.c1})'\n",
    "\n",
    "c1 = C1()\n",
    "print(c1)\n",
    "c2 = C2({'a': 10, 'b': 20, 'c': 30})\n",
    "print(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def weighted_sample_without_replacement_numpy(seq, weights, k):\n",
    "    \"\"\"\n",
    "    Tire au sort un échantillon de k éléments de seq sans remplacement,\n",
    "    en respectant les poids fournis, en utilisant numpy.\n",
    "    \"\"\"\n",
    "    seq = np.array(seq)\n",
    "    weights = np.array(weights, dtype=float)\n",
    "    if k > len(seq):\n",
    "        raise ValueError(\"k ne peut pas être supérieur à la taille de la séquence\")\n",
    "    weights = weights / weights.sum()\n",
    "    indices = np.random.choice(len(seq), size=k, replace=False, p=weights)\n",
    "    return seq[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6, epsilon=1e-6):\n",
    "        self.capacity = capacity\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.states = np.zeros((capacity,), dtype=object)\n",
    "        self.actions = np.zeros((capacity,), dtype=int)\n",
    "        self.rewards = np.zeros((capacity,), dtype=float)\n",
    "        self.next_states = np.zeros((capacity,), dtype=object)\n",
    "        self.dones = np.zeros((capacity,), dtype=bool)\n",
    "        self.priorities = np.zeros((capacity,), dtype=float)\n",
    "        self.pos = 0\n",
    "        self.size = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done, priority=1.0):\n",
    "        idx = self.pos\n",
    "        self.states[idx] = state\n",
    "        self.actions[idx] = action\n",
    "        self.rewards[idx] = reward\n",
    "        self.next_states[idx] = next_state\n",
    "        self.dones[idx] = done\n",
    "        self.priorities[idx] = max(1, priority + self.epsilon) ** self.alpha\n",
    "        self.pos = (self.pos + 1) % self.capacity\n",
    "        self.size = min(self.size + 1, self.capacity)\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        if self.size == 0:\n",
    "            raise ValueError(\"Buffer is empty\")\n",
    "        priorities = self.priorities[:self.size]\n",
    "        probs = priorities / priorities.sum()\n",
    "\n",
    "        indices = np.random.choice(self.size, batch_size, p=probs)\n",
    "\n",
    "        weights = (self.size * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max() # because \"For stability reasons\", page 5 in T. Schaul, J. Quan, I. Antonoglou, and D. Silver, ‘Prioritized Experience Replay’, Feb. 25, 2016, arXiv: arXiv:1511.05952. doi: 10.48550/arXiv.1511.05952.\n",
    "\n",
    "\n",
    "        states = torch.from_numpy(self.states[indices]).float().to(self.device)\n",
    "        actions = torch.from_numpy(self.actions[indices]).long().to(self.device)\n",
    "        rewards = torch.from_numpy(self.rewards[indices]).float().to(self.device)\n",
    "        next_states = torch.from_numpy(self.next_states[indices]).float().to(self.device)\n",
    "        dones = torch.from_numpy(self.dones[indices].astype(np.uint8)).float().to(self.device)\n",
    "        indices = torch.from_numpy(indices).long().to(self.device)\n",
    "        weights = torch.from_numpy(weights).float().to(self.device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones, indices, weights)\n",
    "\n",
    "    def update_priorities(self, indices, priorities):\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            self.priorities[idx] = priority ** self.alpha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity_cnn_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
